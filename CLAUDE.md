# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This is a **JiMeng Web MCP Server** - a TypeScript-based Model Context Protocol (MCP) server that integrates JiMeng AI's image and video generation services. The project directly calls JiMeng's official APIs through reverse engineering, bypassing third-party services.

### Key Features
- **Continue Generation**: Automatically triggers when requesting >4 images, returns all images in a single response
- **Multi-reference Image Generation**: Supports up to 4 reference images for style mixing and fusion
- **Video Generation**: Traditional first/last frame mode, intelligent multi-frame mode, and **main reference mode**
- **Main Reference Video**: NEW! Combines subjects from multiple images (2-4) into one scene using `[å›¾0]`, `[å›¾1]` syntax
- **Video Post-processing**: Frame interpolation, super-resolution, and audio effect generation
- **Zero-install Deployment**: Supports npx auto-installation for Claude Desktop

## Development Commands

### Build & Development
```bash
# Development with hot reload
yarn dev              # or npm run dev

# Build project
yarn build            # or npm run build

# Type checking
yarn type-check       # or npm run type-check

# Development server with auto-restart
yarn start:dev        # or npm run start:dev
```

### Testing
```bash
# Run all tests
yarn test             # or npm run test

# Watch mode for development
yarn test:watch       # or npm run test:watch

# Coverage report
yarn test:coverage    # or npm run test:coverage

# Test individual files
yarn test image-generation.test.ts
yarn test video-generation.test.ts

# MCP server testing
yarn test:mcp         # or npm run test:mcp
```

### Running the Server
```bash
# Start MCP server (stdio mode)
yarn start            # or npm run start

# Start as HTTP API service
yarn start:api        # or npm run start:api
```

## Architecture Overview

### Core Module Structure
The project follows a **composition-based architecture** after a comprehensive refactoring that reduced code by 74.6% (from 5,268 to 1,335 lines):

- **`src/api.ts`** - Main entry point with backward-compatible exports
- **`src/server.ts`** - MCP server implementation with tool definitions
- **`src/api/NewJimengClient.ts`** - Main API client using composition pattern (351 lines)
- **`src/api/HttpClient.ts`** - Centralized HTTP client with authentication (256 lines)
- **`src/api/ImageUploader.ts`** - Image upload service using image-size library (221 lines)
- **`src/api/NewCreditService.ts`** - Credit management using composition (114 lines)
- **`src/api/VideoService.ts`** - Unified video generation service (393 lines)
  - Merges all video generation modes (text-to-video, multi-frame, main reference)
  - Inline polling logic (~25 lines, replacing 249-line timeout abstraction)
- **`src/types/api.types.ts`** - Complete API type definitions (200 lines)
- **`src/types/models.ts`** - Model mappings and constants (80 lines)
- **`src/utils/`** - Authentication, dimension calculation, logging utilities
- **`src/schemas/video.schemas.ts`** - Zod validation schemas for MCP tool parameters only

**Removed Components** (74.6% code reduction):
- âŒ `BaseClient.ts` (748 lines) - Replaced by HttpClient + ImageUploader
- âŒ `VideoGenerator.ts` (1,676 lines) - Merged into VideoService
- âŒ `TextToVideoGenerator.ts` (378 lines) - Merged into VideoService
- âŒ `MultiFrameVideoGenerator.ts` (467 lines) - Merged into VideoService
- âŒ `MainReferenceVideoGenerator.ts` (710 lines) - Merged into VideoService
- âŒ `timeout.ts` (249 lines) - Inlined polling logic (~25 lines)
- âŒ `deprecation.ts` (150 lines) - Completely removed

### Key Architectural Patterns

**Composition Over Inheritance**: The architecture uses dependency injection instead of inheritance chains:
```typescript
class NewJimengClient {
  private httpClient: HttpClient
  private imageUploader: ImageUploader
  private creditService: NewCreditService
  private videoService: VideoService

  constructor(token?: string) {
    this.httpClient = new HttpClient(token);
    this.imageUploader = new ImageUploader(this.httpClient);
    this.creditService = new NewCreditService(this.httpClient);
    this.videoService = new VideoService(this.httpClient, this.imageUploader);
  }
}
```

**Single Responsibility**: Each service class has a clear, focused purpose:
- **HttpClient**: HTTP requests and authentication (no inheritance)
- **ImageUploader**: Image upload and format detection using image-size library
- **NewCreditService**: Credit/point management (composition, not inheritance)
- **VideoService**: All video generation modes in one unified service
- **NewJimengClient**: Main API facade, delegates to specialized services

**Unified Service Pattern**: VideoService consolidates all video generation:
- Text-to-video with optional first/last frame support
- Multi-frame video generation (2-10 frames)
- Main reference video with [å›¾N] syntax
- Shared internal methods for upload, submission, and polling
- Inline polling logic with exponential backoff (2s â†’ 10s, 1.5x factor, 600s timeout)

**Singleton Pattern**: The `getApiClient()` function maintains a global client instance for backward compatibility.

**Unified Async/Sync Pattern**: All new video generation methods support a single `async` parameter instead of separate async methods. When `async=false`, the system uses conditional polling with 600s timeout and exponential backoff (2sâ†’10s, 1.5x factor).

**Type Safety**: Comprehensive TypeScript definitions with Zod validation for MCP tool parameters.

**Modular Design**: Separates concerns into distinct modules while maintaining 100% backward compatibility.

### Continue Generation Implementation
The continue generation feature is implemented in `src/api/JimengClient.ts` around the `generateImage` method:
- Automatically detects when `total_image_count > 4`
- Makes single additional API call to generate remaining images
- Waits for completion and returns combined results
- Transparent to users - no configuration needed

### Multi-Reference Image System
Supports complex image mixing through:
- **Single Reference**: Automatic `##` prefix in prompt
- **Multi-Reference**: Automatic `####` prefix for up to 4 images
- **File Path Support**: Local absolute/relative paths and URLs
- **Strength Control**: Individual strength per reference image

## MCP Tools Available (10 Core Tools)

### ğŸ¨ Image Generation (2 tools)
- **`image`**: Generate single image (default: sync)
  - Fast single image generation with reference image support
  - Supports up to 4 reference images for style mixing
  - Default async: `false` (synchronous)

- **`image_batch`**: Series image generation (default: async)
  - **ä¸“ç”¨äºé«˜ç›¸å…³æ€§ç³»åˆ—å›¾ç‰‡**ï¼šåŒä¸€æˆ¿å­ä¸åŒç©ºé—´ã€æ•…äº‹åˆ†é•œã€ç»˜æœ¬ç”»é¢ã€äº§å“å¤šè§’åº¦
  - **promptså†™æ³•**ï¼šæ¯ä¸ªå…ƒç´ æ˜¯ä¸€å°æ®µè¯ï¼ˆä¸æ˜¯å•ä¸ªè¯ï¼‰ï¼Œé‡ç‚¹æè¿°å›¾ä¸å›¾çš„å·®å¼‚
  - Final prompt format: `ç¬¬1å¼ ï¼šxxx ç¬¬2å¼ ï¼šyyyï¼Œä¸€å…±Nå¼ å›¾`
  - Automatic continue generation for counts > 4
  - Default async: `true` (asynchronous)

  **é€‚ç”¨åœºæ™¯**ï¼š
  - âœ… åŒä¸€å¥—æˆ¿å­çš„ä¸åŒç©ºé—´ç…§ç‰‡ï¼ˆå®¢å…ã€å§å®¤ã€å¨æˆ¿ï¼‰
  - âœ… ä¸€ä¸ªæ•…äº‹çš„è¿ç»­åˆ†é•œï¼ˆåœºæ™¯1ã€åœºæ™¯2ã€åœºæ™¯3ï¼‰
  - âœ… ä¸€ä¸ªç»˜æœ¬çš„ä¸åŒç”»é¢ï¼ˆç¬¬1é¡µã€ç¬¬2é¡µã€ç¬¬3é¡µï¼‰
  - âœ… åŒä¸€ç‰©å“çš„ä¸åŒè§’åº¦ç…§ç‰‡ï¼ˆæ­£é¢ã€ä¾§é¢ã€èƒŒé¢ï¼‰

  **å‚æ•°è¯´æ˜**ï¼š
  - **prompts**: æ¯å¼ å›¾çš„å·®å¼‚æè¿°ï¼ˆä¸€å°æ®µè¯ï¼‰
  - **basePrompt**: æ•´ä½“é€šç”¨æè¿°ï¼ˆå¯é€‰ï¼‰ï¼Œä¼šæ·»åŠ åœ¨æœ€ç»ˆpromptæœ€å‰é¢
    - æˆ¿é—´ç³»åˆ— â†’ æè¿°æ•´ä½“é£æ ¼ã€æˆ·å‹
    - äº§å“å¤šè§’åº¦ â†’ æè¿°äº§å“æè´¨ã€é¢œè‰²ã€å“ç‰Œ
    - æ•…äº‹åˆ†é•œ â†’ æè¿°ä¸–ç•Œè§‚ã€è§’è‰²ç‰¹å¾
    - ç»˜æœ¬ç”»é¢ â†’ æè¿°ç”»é£ã€è‰²è°ƒ

  **æ­£ç¡®ç¤ºä¾‹1 - æˆ¿é—´ç³»åˆ—**ï¼š
  ```json
  {
    "basePrompt": "ä¸‰å®¤ä¸¤å…ç°ä»£ç®€çº¦é£æ ¼ï¼Œæœ¨åœ°æ¿ï¼Œæš–è‰²è°ƒç…§æ˜ï¼Œç®€çº¦å®¶å…·",
    "prompts": [
      "å®¢å…ï¼Œç°è‰²å¸ƒè‰ºæ²™å‘é çª—ï¼Œè½åœ°çª—æ´’å…¥é˜³å…‰ï¼ŒèŒ¶å‡ ä¸Šæ”¾ç€æ‚å¿—",
      "ä¸»å§å®¤ï¼Œç±³è‰²åºŠå“æ•´é½é“ºå±•ï¼Œæœ¨è´¨åºŠå¤´æŸœä¸Šæœ‰å°ç¯ï¼Œå¢™é¢æ·¡è“è‰²",
      "å¼€æ”¾å¼å¨æˆ¿ï¼Œç™½è‰²æ©±æŸœæ•´é½æ’åˆ—ï¼Œå¤§ç†çŸ³å°é¢ï¼Œä¸­å²›å°ä¸Šæ‘†æ”¾æ°´æœç¯®"
    ],
    "async": true
  }
  ```
  **æœ€ç»ˆprompt**: "ä¸‰å®¤ä¸¤å…ç°ä»£ç®€çº¦é£æ ¼ï¼Œæœ¨åœ°æ¿ï¼Œæš–è‰²è°ƒç…§æ˜ï¼Œç®€çº¦å®¶å…· ç¬¬1å¼ ï¼šå®¢å…ï¼Œç°è‰²å¸ƒè‰ºæ²™å‘é çª—... ç¬¬2å¼ ï¼šä¸»å§å®¤... ç¬¬3å¼ ï¼šå¼€æ”¾å¼å¨æˆ¿...ï¼Œä¸€å…±3å¼ å›¾"

  **æ­£ç¡®ç¤ºä¾‹2 - äº§å“å¤šè§’åº¦**ï¼š
  ```json
  {
    "basePrompt": "è‹¹æœAirPods Pro 2ä»£ï¼Œç™½è‰²é™¶ç“·æè´¨ï¼Œç£¨ç ‚è´¨æ„Ÿï¼Œè‹¹æœlogo",
    "prompts": [
      "æ­£é¢ç‰¹å†™ï¼Œå……ç”µç›’å¼€ç›–ï¼Œè€³æœºåœ¨ç›’å†…ï¼ŒLEDæŒ‡ç¤ºç¯å¯è§",
      "ä¾§é¢45åº¦è§’ï¼Œå±•ç¤ºå……ç”µç›’åšåº¦å’Œåœ†æ¶¦è¾¹ç¼˜ï¼Œè€³æœºæŸ„éœ²å‡º",
      "èƒŒé¢è§†è§’ï¼Œå……ç”µå£ç‰¹å†™ï¼Œåºåˆ—å·åŒºåŸŸæ¸…æ™°ï¼Œç£å¸æ¥è§¦ç‚¹"
    ]
  }
  ```

  **é”™è¯¯ç¤ºä¾‹** âŒï¼š
  ```json
  {
    "prompts": ["å®¢å…", "å§å®¤", "å¨æˆ¿"]  // è¿‡åˆ†ç®€çŸ­ï¼Œç¼ºå°‘å·®å¼‚æè¿°
  }
  ```

### ğŸ¬ Video Generation (4 tools)
- **`video`**: Pure text-to-video generation (default: async)
  - Generate video from text description only
  - No reference images required
  - Default async: `true`

- **`video_frame`**: First/last frame controlled video (default: async)
  - Control video start and/or end frames
  - Supports first frame only, last frame only, or both
  - Default async: `true`

- **`video_multi`**: Multi-frame precision control (default: async)
  - **å·¥ä½œåŸç†**: æä¾›2-10ä¸ªå…³é”®å¸§å›¾ç‰‡ï¼Œç³»ç»Ÿåœ¨å¸§é—´ç”Ÿæˆå¹³æ»‘è¿‡æ¸¡åŠ¨ç”»
  - **âš ï¸ é‡è¦**: promptæè¿°çš„æ˜¯"ä»å½“å‰å¸§åˆ°ä¸‹ä¸€å¸§çš„è¿‡æ¸¡è¿‡ç¨‹"ï¼Œå¿…é¡»åŒ…å«ï¼š
    1. **é•œå¤´ç§»åŠ¨**ï¼šæ¨è¿›ã€æ‹‰è¿œã€æ‘‡ç§»ã€è·Ÿéšç­‰
    2. **ç”»é¢å˜åŒ–**ï¼šä¸»ä½“åŠ¨ä½œã€åœºæ™¯å˜åŒ–ã€å…‰å½±å˜åŒ–
    3. **è½¬åœºæ•ˆæœ**ï¼šæ·¡å…¥æ·¡å‡ºã€åˆ‡æ¢æ–¹å¼ç­‰
  - **âš ï¸ æ³¨æ„**: æœ€åä¸€å¸§çš„promptä¸ç”Ÿæ•ˆï¼ˆå› ä¸ºæ²¡æœ‰ä¸‹ä¸€å¸§äº†ï¼‰ï¼Œå¯ä»¥ç•™ç©ºæˆ–éšæ„å¡«å†™
  - **æ—¶é•¿é™åˆ¶**: æ¯å¸§1-6ç§’ï¼ˆ1000-6000æ¯«ç§’ï¼‰ï¼Œæ€»æ—¶é•¿â‰¤15ç§’
  - Default async: `true`

  **å‚æ•°è¯´æ˜**:
  ```typescript
  {
    frames: [
      {
        idx: 0,                           // å¸§åºå·ï¼Œä»0å¼€å§‹
        imagePath: "/abs/path/frame0.jpg", // ç»å¯¹è·¯å¾„
        duration_ms: 2000,                 // è¿™æ®µè¿‡æ¸¡åŠ¨ç”»çš„æ—¶é•¿ï¼ˆæ¯«ç§’ï¼Œ1000-6000ï¼‰
        prompt: "é•œå¤´ä»æ­£é¢ç¼“æ…¢æ¨è¿›ï¼ŒçŒ«ä»åå§¿ç«™èµ·ï¼Œå…‰çº¿ä»å·¦ä¾§ç…§å…¥"  // æè¿°0â†’1çš„é•œå¤´ã€åŠ¨ä½œã€è½¬åœº
      },
      {
        idx: 1,
        imagePath: "/abs/path/frame1.jpg",
        duration_ms: 2000,
        prompt: "çŒ«å‘å‰è¿ˆæ­¥è¡Œèµ°ï¼Œå°¾å·´æ‘‡æ‘†"  // æè¿°1â†’2çš„å˜æ¢è¿‡ç¨‹
      },
      {
        idx: 2,
        imagePath: "/abs/path/frame2.jpg",
        duration_ms: 1000,
        prompt: "ï¼ˆæ­¤promptä¸ç”Ÿæ•ˆï¼Œå¯ç•™ç©ºï¼‰"  // æœ€åä¸€å¸§ï¼Œæ— ä¸‹ä¸€å¸§
      }
    ],
    fps: 24,
    resolution: "720p"
  }
  ```

  **ç”Ÿæˆæ•ˆæœ** (æ€»æ—¶é•¿5ç§’):
  - 0-2ç§’: æ˜¾ç¤ºframe0 + æ‰§è¡Œ"ç«™èµ·æ¥"åŠ¨ç”» â†’ æ¸å˜åˆ°frame1
  - 2-4ç§’: æ˜¾ç¤ºframe1 + æ‰§è¡Œ"è¡Œèµ°"åŠ¨ç”» â†’ æ¸å˜åˆ°frame2
  - 4-5ç§’: æ˜¾ç¤ºframe2ä½œä¸ºç»“å°¾ç”»é¢

- **`video_mix`**: Multi-image subject fusion (default: async)
  - Combine subjects from 2-4 reference images into one scene
  - Use `[å›¾0]`, `[å›¾1]` syntax to reference images
  - Example: `[å›¾0]çš„çŒ«åœ¨[å›¾1]çš„åœ°æ¿ä¸Šè·‘`
  - Default async: `true`

### ğŸ” Query Tools (2 tools)
- **`query`**: Query single task status and result
  - Supports both image and video tasks
  - Returns status, progress, and URLs when completed

- **`query_batch`**: Batch query multiple tasks
  - Query up to 10 tasks at once
  - Efficient for checking multiple tasks

### ğŸ“ Utility Tools (1 tool)
- **`ping`**: Test server connection
  - Health check and connectivity test

### ğŸ—‘ï¸ Removed Legacy Tools
The following tools have been removed in favor of the new unified tools:
- âŒ `generateImage` â†’ use `image` or `image_batch`
- âŒ `generateVideo` â†’ use `video`, `video_frame`, or `video_multi`
- âŒ `generateTextToVideo` â†’ use `video` or `video_frame`
- âŒ `generateMultiFrameVideo` â†’ use `video_multi`
- âŒ `generateMainReferenceVideo` â†’ use `video_mix`
- âŒ `generateMainReferenceVideoUnified` â†’ use `video_mix`
- âŒ `videoPostProcess` â†’ deprecated
- âŒ All `*Async` tools â†’ use `async: true` parameter instead
- âŒ `hello` â†’ use `ping`
- âŒ `greeting` resource â†’ removed
- âŒ `info` resource â†’ removed

### Default Async Behavior
- **Sync by default (1 tool)**: `image` - fast single image generation
- **Async by default (6 tools)**: All other generation tools default to async mode
  - `image_batch`, `video`, `video_frame`, `video_multi`, `video_mix`
  - All support `async: false` to switch to sync mode if needed

## Testing Strategy

### Test Categories
- **Unit Tests**: Individual component testing (`clients.test.ts`, `utilities.test.ts`)
- **Integration Tests**: Full API flow testing (`integration.test.ts`, `simple-integration.test.ts`)
- **Async Tests**: Non-blocking API testing (`async-*.test.ts`)
- **Build Verification**: Ensures build process works correctly
- **Backward Compatibility**: Verifies refactoring maintains compatibility

### Test Configuration
- Uses Jest with TypeScript support
- ES module compatibility with `.js` extension handling
- Coverage collection excludes type definitions and test files
- Mock configuration for network requests

## Environment Configuration

### Required Environment Variables
```bash
JIMENG_API_TOKEN=your_session_id_from_jimeng_cookies
```

### Getting API Token
1. Visit [JiMeng AIå®˜ç½‘](https://jimeng.jianying.com) and login
2. Open browser dev tools (F12)
3. Go to Application > Cookies
4. Find `sessionid` value and set as `JIMENG_API_TOKEN`

### MCP Configuration (Claude Desktop)
```json
{
  "mcpServers": {
    "jimeng-web-mcp": {
      "command": "npx",
      "args": ["-y", "--package=jimeng-web-mcp", "jimeng-web-mcp"],
      "env": {
        "JIMENG_API_TOKEN": "your_session_id_here"
      }
    }
  }
}
```

## Model Support

### Image Models
- `jimeng-4.0` (recommended) - Latest model with enhanced capabilities
- `jimeng-3.0` - Rich aesthetic diversity, more vivid images
- `jimeng-2.1` - Default model, balanced performance
- `jimeng-2.0-pro` - Pro version for advanced use cases
- `jimeng-1.4` - Legacy model support
- `jimeng-xl-pro` - Special XL version

### Video Models
- `jimeng-video-3.0` - Main video generation model (default)
- `jimeng-video-3.0-pro` - High-quality video generation
- `jimeng-video-2.0-pro` - Compatible with multiple scenarios
- `jimeng-video-2.0` - Basic video generation

## Common Development Tasks

### Adding New Image Generation Tools
1. Define tool in `src/server.ts` using Zod schemas
2. Add corresponding function in `src/api/JimengClient.ts`
3. Update type definitions in `src/types/api.types.ts`
4. Add tests in appropriate test file

### Adding New Video Generation Tools
1. Create dedicated generator class in `src/api/video/` extending `VideoGenerator`
2. Define tool in `src/server.ts` using Zod schemas from `src/schemas/video.schemas.ts`
3. Update type definitions in `src/types/api.types.ts`
4. Expose method through JimengClient delegation
5. Add tests in appropriate test file (unit/, integration/, e2e/)
6. Add timeout and error handling using shared utilities

### Testing API Changes
1. Use existing async test patterns for network-dependent tests
2. Mock network requests for unit testing
3. Verify backward compatibility with integration tests
4. Run full test suite before committing

### Build Process
- Uses `tsup` for bundling with dual CJS/ESM output
- Generates TypeScript declarations automatically
- Clean build removes previous artifacts
- Source maps included for debugging

## Important Notes

- **Backward Compatibility**: All changes must maintain 100% compatibility with existing API
- **Unified Async/Sync API**: New video methods use single `async` parameter instead of separate async methods
- **Soft Deprecation**: Legacy methods show warnings but remain functional using `warnOnce` system
- **Timeout Management**: Synchronous operations use 600s timeout with exponential backoff (2sâ†’10s, 1.5x factor)
- **Zero-install**: The npx deployment method is preferred over manual installation
- **Security**: Never commit API tokens or sensitive information
- **Performance**: The singleton pattern prevents duplicate client instances
- **Error Handling**: Comprehensive error handling with user-friendly messages
- **Modular Testing**: Three-tier testing strategy (unit â†’ integration â†’ e2e) ensures reliability

## Main Reference Video Generation (NEW Feature)

### Overview

**Main Reference Video** is a NEW video generation mode that allows combining subjects from multiple images (2-4) into a single scene. It enables precise control over which elements from each reference image to use.

### Key Capabilities

- **Multi-Image Subject Fusion**: Extract subjects from different images and place them in one scene
- **Precise Reference Control**: Use `[å›¾0]`, `[å›¾1]`, `[å›¾2]`, `[å›¾3]` syntax to reference specific images
- **Flexible Composition**: Mix characters, objects, and environments from different sources
- **Natural Language Prompts**: Describe the desired scene using natural language with image references

### Usage Examples

#### Example 1: Character in Different Environment
```typescript
// Combine a cat from image 1 with a floor from image 2
{
  referenceImages: ["/path/to/cat.jpg", "/path/to/floor.jpg"],
  prompt: "[å›¾0]ä¸­çš„çŒ«åœ¨[å›¾1]çš„åœ°æ¿ä¸Šè·‘",
  // Translation: "The cat from [image 0] running on the floor from [image 1]"
}
```

#### Example 2: Multiple Subject Composition
```typescript
{
  referenceImages: [
    "/path/to/person.jpg",
    "/path/to/car.jpg",
    "/path/to/beach.jpg"
  ],
  prompt: "[å›¾0]ä¸­çš„äººååœ¨[å›¾1]çš„è½¦é‡Œï¼ŒèƒŒæ™¯æ˜¯[å›¾2]çš„æµ·æ»©",
  // "Person from image 0 sitting in car from image 1, with beach from image 2 as background"
}
```

#### Example 3: Object Replacement
```typescript
{
  referenceImages: ["/path/to/room.jpg", "/path/to/furniture.jpg"],
  prompt: "[å›¾0]çš„æˆ¿é—´é‡Œæ”¾ç€[å›¾1]çš„å®¶å…·",
  // "Room from image 0 with furniture from image 1"
}
```

### Parameter Reference

```typescript
interface MainReferenceVideoParams {
  referenceImages: string[];          // 2-4 image file paths (absolute paths)
  prompt: string;                     // Prompt with [å›¾N] syntax to reference images
  model?: string;                     // Default: "jimeng-video-3.0"
  resolution?: '720p' | '1080p';      // Default: '720p'
  videoAspectRatio?: '21:9' | '16:9' | '4:3' | '1:1' | '3:4' | '9:16';  // Default: '16:9'
  fps?: number;                       // Frame rate 12-30, default: 24
  duration?: number;                  // Duration in ms, 3000-15000, default: 5000
}
```

### Important Notes

1. **Image Count**: Requires 2-4 reference images (less than 2 or more than 4 will fail)
2. **Prompt Requirements**: Must include at least one image reference using `[å›¾N]` syntax
3. **Valid Indices**: Image indices must be valid (0-based, within range of provided images)
4. **Model Support**: Requires jimeng-video-3.0 or later models
5. **Processing Time**: May take longer than traditional video generation due to multi-image processing

### Technical Details

#### Architecture
- **Location**: `src/api/video/MainReferenceVideoGenerator.ts`
- **Inheritance**: Extends `JimengClient` to reuse upload and request capabilities
- **Independence**: Fully independent implementation, no modifications to existing code

#### Implementation Features
- Automatic prompt parsing to extract image references and text segments
- Converts `[å›¾N]` syntax to API's `idip_meta_list` structure
- Uploads all reference images before generation
- Polls video generation status with exponential backoff
- Comprehensive parameter validation

#### API Mapping
The tool translates user-friendly syntax into JiMeng's internal format:
- `video_mode: 2` - Identifies main reference mode
- `idip_frames` - Uploaded reference images
- `idip_meta_list` - Structured prompt with image references and text segments
- `functionMode: "main_reference"` - Tracking metadata

### Error Handling

Common errors and solutions:

| Error | Cause | Solution |
|-------|-------|----------|
| "è‡³å°‘éœ€è¦2å¼ å‚è€ƒå›¾ç‰‡" | Less than 2 images provided | Provide 2-4 images |
| "æœ€å¤šæ”¯æŒ4å¼ å‚è€ƒå›¾ç‰‡" | More than 4 images provided | Reduce to 4 or fewer |
| "å¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªå›¾ç‰‡å¼•ç”¨" | No `[å›¾N]` in prompt | Add image references like `[å›¾0]` |
| "å›¾ç‰‡å¼•ç”¨[å›¾N]è¶…å‡ºèŒƒå›´" | Index exceeds image count | Use valid indices (0 to imageCount-1) |
| "ä¸Šä¼ å¤±è´¥" | Image file not found/accessible | Check file paths are absolute and valid |

### MCP Tool Registration

The feature is registered as `generateMainReferenceVideo` in MCP server:
```typescript
server.tool("generateMainReferenceVideo", ...)
```

Available in Claude Desktop once MCP server is configured.

## Video Generation API Reference (Feature 005-3-1-2)

### Overview

The video generation API has been refactored into three specialized methods, each supporting unified async/sync operation through a single `async` parameter.

### New Video Generation Methods

#### 1. generateTextToVideo

Text-to-video generation with optional first/last frame support.

```typescript
// Usage in Claude Desktop
generateTextToVideo({
  prompt: "A beautiful sunset over mountains",
  model: "jimeng-video-3.0",
  resolution: "1080p",
  videoAspectRatio: "16:9",
  fps: 24,
  duration: 5000,
  async: false,  // Sync mode (default)
  firstFrameImage: "/path/to/first.jpg",  // Optional
  lastFrameImage: "/path/to/last.jpg"    // Optional
})
```

**Key Features:**
- **Text-to-Video**: Generate video from text description
- **First/Last Frame**: Optional control over start and end frames
- **Unified Async**: Single `async` parameter for sync/async modes
- **600s Timeout**: Automatic polling with exponential backoff for sync mode

#### 2. generateMultiFrameVideo

Multi-frame video generation with precise control over 2-10 frames.

```typescript
generateMultiFrameVideo({
  frames: [
    {
      idx: 0,
      imagePath: "/frame-0.jpg",
      duration_ms: 1000,
      prompt: "Starting scene"
    },
    {
      idx: 1,
      imagePath: "/frame-1.jpg",
      duration_ms: 1000,
      prompt: "Middle scene"
    },
    {
      idx: 2,
      imagePath: "/frame-2.jpg",
      duration_ms: 1000,
      prompt: "Ending scene"
    }
  ],
  prompt: "Smooth transition between frames",
  model: "jimeng-video-3.0",
  resolution: "720p",
  fps: 24,
  duration: 8000,
  async: false
})
```

**Key Features:**
- **2-10 Frames**: Precise control over frame sequence
- **Frame Timing**: Individual duration control per frame
- **Automatic Sorting**: Frames automatically sorted by index
- **Validation**: Comprehensive parameter validation

#### 3. generateMainReferenceVideo

Main reference video generation using [å›¾N] syntax for multi-image composition.

```typescript
generateMainReferenceVideo({
  referenceImages: [
    "/path/to/person.jpg",
    "/path/to/car.jpg",
    "/path/to/beach.jpg"
  ],
  prompt: "[å›¾0]ä¸­çš„äººååœ¨[å›¾1]çš„è½¦é‡Œï¼ŒèƒŒæ™¯æ˜¯[å›¾2]çš„æµ·æ»©",
  model: "jimeng-video-3.0",
  resolution: "1080p",
  videoAspectRatio: "16:9",
  fps: 24,
  duration: 5000,
  async: false
})
```

**Key Features:**
- **Multi-Image Fusion**: Combine subjects from 2-4 reference images
- **[å›¾N] Syntax**: Natural language with precise image references
- **Smart Parsing**: Automatic extraction of image references
- **Validation**: Ensures valid indices and required image references

### Async/Sync Pattern

All new methods use the unified async parameter:

```typescript
// Synchronous mode (async: false)
const result = await generateTextToVideo({
  prompt: "Test video",
  async: false
});
// Returns: { videoUrl: "...", metadata: {...} }

// Asynchronous mode (async: true)
const result = await generateTextToVideo({
  prompt: "Test video",
  async: true
});
// Returns: { taskId: "..." }
```

### Common Parameters

All video generation methods support these common parameters:

- **async**: boolean - Sync (false) or async (true) mode
- **model**: string - Video model (default: "jimeng-video-3.0")
- **resolution**: "720p" | "1080p" - Video resolution
- **videoAspectRatio**: "21:9" | "16:9" | "4:3" | "1:1" | "3:4" | "9:16"
- **fps**: number (12-30) - Frame rate
- **duration**: number (3000-15000) - Duration in milliseconds

### Error Handling

Consistent error format across all methods:

```typescript
{
  error: {
    code: "TIMEOUT" | "CONTENT_VIOLATION" | "API_ERROR" | "INVALID_PARAMS" | "PROCESSING_FAILED" | "UNKNOWN",
    message: "Human-readable error message",
    reason: "Detailed explanation",
    taskId?: string,
    timestamp: number
  }
}
```

### Migration from Legacy Methods

Legacy `generateVideo` method is deprecated but still functional:

```typescript
// Legacy method (shows deprecation warning)
generateVideo({...}) // Automatically redirects to appropriate new method

// New recommended methods
generateTextToVideo({...})        // For text-based generation
generateMultiFrameVideo({...})    // For multi-frame generation
generateMainReferenceVideo({...}) // For multi-image composition
```

### Timeout and Polling

Synchronous operations use intelligent polling:
- **Initial Interval**: 2 seconds
- **Max Interval**: 10 seconds
- **Backoff Factor**: 1.5x
- **Total Timeout**: 600 seconds (10 minutes)
- **Network Recovery**: Automatic retry on transient failures

## Task Master AI Instructions
**Import Task Master's development workflow commands and guidelines, treat as if import is in the main CLAUDE.md file.**
@./.taskmaster/CLAUDE.md
